"""Vulnerability database for known ML model vulnerabilities."""

from dataclasses import dataclass
from typing import Dict, List, Optional, Set
from .base import Severity


@dataclass
class VulnerabilityEntry:
    """Entry in the vulnerability database."""
    id: str
    name: str
    description: str
    severity: Severity
    cve_id: Optional[str] = None
    cwe_id: Optional[str] = None
    affected_frameworks: List[str] = None
    affected_versions: Dict[str, str] = None  # framework -> version range
    detection_patterns: List[str] = None
    remediation: Optional[str] = None
    references: List[str] = None


class VulnerabilityDatabase:
    """Database of known ML model vulnerabilities."""
    
    def __init__(self):
        """Initialize vulnerability database."""
        self._vulnerabilities: Dict[str, VulnerabilityEntry] = {}
        self._by_cve: Dict[str, VulnerabilityEntry] = {}
        self._by_framework: Dict[str, List[VulnerabilityEntry]] = {}
        self._initialize_database()
        
    def _initialize_database(self):
        """Initialize with known vulnerabilities."""
        vulnerabilities = [
            VulnerabilityEntry(
                id="LLMS-2019-001",
                name="Pickle Arbitrary Code Execution",
                description="Pickle deserialization can execute arbitrary code when loading untrusted data",
                severity=Severity.CRITICAL,
                cve_id="CVE-2019-20907",
                cwe_id="CWE-502",
                affected_frameworks=["pytorch", "tensorflow", "scikit-learn"],
                detection_patterns=["pickle.loads", "pickle.load", "__reduce__", "__setstate__"],
                remediation="Use safe serialization formats like JSON or safetensors instead of pickle"
            ),
            VulnerabilityEntry(
                id="LLMS-2022-001",
                name="PyTorch JIT Code Execution",
                description="torch.jit.load() can execute arbitrary code embedded in model files",
                severity=Severity.CRITICAL,
                cve_id="CVE-2022-45907",
                cwe_id="CWE-94",
                affected_frameworks=["pytorch"],
                affected_versions={"pytorch": "<1.13.0"},
                detection_patterns=["torch.jit.load", "__code__", "exec"],
                remediation="Update PyTorch to version 1.13.0 or later"
            ),
            VulnerabilityEntry(
                id="LLMS-2021-001",
                name="TensorFlow Code Execution via Checkpoint",
                description="TensorFlow checkpoint loading can execute arbitrary code",
                severity=Severity.HIGH,
                cve_id="CVE-2021-22926",
                cwe_id="CWE-20",
                affected_frameworks=["tensorflow"],
                affected_versions={"tensorflow": "<2.6.0"},
                remediation="Update TensorFlow to version 2.6.0 or later"
            ),
            VulnerabilityEntry(
                id="LLMS-2024-001",
                name="ONNX Buffer Overflow",
                description="Buffer overflow in ONNX Runtime shape inference",
                severity=Severity.HIGH,
                cve_id="CVE-2024-27318",
                cwe_id="CWE-120",
                affected_frameworks=["onnx"],
                detection_patterns=["malformed_shape", "negative_dimension"],
                remediation="Validate ONNX model structure before loading"
            ),
            VulnerabilityEntry(
                id="LLMS-PATTERN-001",
                name="Suspicious Import Pattern",
                description="Model contains imports of dangerous modules like os, subprocess",
                severity=Severity.HIGH,
                cwe_id="CWE-94",
                affected_frameworks=["all"],
                detection_patterns=["import os", "import subprocess", "import socket"],
                remediation="Review model code and remove unnecessary system imports"
            ),
            VulnerabilityEntry(
                id="LLMS-PATTERN-002",
                name="Hidden Layer Backdoor",
                description="Model contains suspicious layer names indicating potential backdoor",
                severity=Severity.MEDIUM,
                cwe_id="CWE-506",
                affected_frameworks=["pytorch", "tensorflow"],
                detection_patterns=["backdoor", "trigger", "malicious", "payload"],
                remediation="Inspect model architecture and retrain from trusted data"
            ),
            VulnerabilityEntry(
                id="LLMS-PATTERN-003",
                name="Eval/Exec Code Pattern",
                description="Model contains eval() or exec() calls that can execute arbitrary code",
                severity=Severity.CRITICAL,
                cwe_id="CWE-95",
                affected_frameworks=["all"],
                detection_patterns=["eval(", "exec(", "compile("],
                remediation="Remove all eval/exec calls and refactor code"
            ),
            VulnerabilityEntry(
                id="LLMS-SUPPLY-001",
                name="Known Malicious Model",
                description="Model matches known malicious model signatures",
                severity=Severity.CRITICAL,
                affected_frameworks=["all"],
                detection_patterns=["mcpotato/42-eicar-street", "eicar-test-signature"],
                remediation="Do not use this model. It is known to be malicious."
            )
        ]
        
        for vuln in vulnerabilities:
            self.add_vulnerability(vuln)
            
    def add_vulnerability(self, vuln: VulnerabilityEntry):
        """Add a vulnerability to the database."""
        self._vulnerabilities[vuln.id] = vuln
        
        if vuln.cve_id:
            self._by_cve[vuln.cve_id] = vuln
            
        if vuln.affected_frameworks:
            for framework in vuln.affected_frameworks:
                if framework not in self._by_framework:
                    self._by_framework[framework] = []
                self._by_framework[framework].append(vuln)
                
    def get_by_id(self, vuln_id: str) -> Optional[VulnerabilityEntry]:
        """Get vulnerability by ID."""
        return self._vulnerabilities.get(vuln_id)
        
    def get_by_cve(self, cve_id: str) -> Optional[VulnerabilityEntry]:
        """Get vulnerability by CVE ID."""
        return self._by_cve.get(cve_id)
        
    def get_by_framework(self, framework: str) -> List[VulnerabilityEntry]:
        """Get vulnerabilities affecting a specific framework."""
        vulns = self._by_framework.get(framework.lower(), [])
        # Also include 'all' framework vulnerabilities
        vulns.extend(self._by_framework.get('all', []))
        return vulns
        
    def search_by_pattern(self, pattern: str) -> List[VulnerabilityEntry]:
        """Search vulnerabilities by pattern."""
        results = []
        pattern_lower = pattern.lower()
        
        for vuln in self._vulnerabilities.values():
            if vuln.detection_patterns:
                for det_pattern in vuln.detection_patterns:
                    if pattern_lower in det_pattern.lower():
                        results.append(vuln)
                        break
                        
        return results
        
    def get_all(self) -> List[VulnerabilityEntry]:
        """Get all vulnerabilities."""
        return list(self._vulnerabilities.values())
        
    def check_version(self, framework: str, version: str, vuln: VulnerabilityEntry) -> bool:
        """Check if a specific version is affected by a vulnerability."""
        if not vuln.affected_versions or framework not in vuln.affected_versions:
            return True  # Assume vulnerable if no version info
            
        version_range = vuln.affected_versions[framework]
        # Simple version check - in production, use proper version parsing
        if version_range.startswith('<'):
            return True  # Simplified - assume vulnerable
        return False


# Global instance
vulnerability_db = VulnerabilityDatabase()